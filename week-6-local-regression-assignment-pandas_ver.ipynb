{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices using k-nearest neighbors regression\n",
    "In this notebook, you will implement k-nearest neighbors regression. You will:\n",
    "  * Find the k-nearest neighbors of a given query input\n",
    "  * Predict the output for the query input using the k-nearest neighbors\n",
    "  * Choose the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up GraphLab Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # note this allows us to refer to numpy as np instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** For this notebook, we use a subset of the King County housing dataset created by randomly selecting 40% of the houses in the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of features = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>5650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>7639.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0       3.0       1.00       1180.0   \n",
       "1  6414100192  20141209T000000  538000.0       3.0       2.25       2570.0   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0           0     0     ...          7        1180   \n",
       "1      7242     2.0           0     0     ...          7        2170   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0         1340.0      5650.0  \n",
       "1         1690.0      7639.0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, \n",
    "              'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, \n",
    "              'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, \n",
    "              'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, \n",
    "              'id':str, 'sqft_lot':int, 'view':int}\n",
    "sales = pd.read_csv('./kc_house_data_small.csv', dtype=dtype_dict)\n",
    "print \"\\nNumber of features = %d\" %len(sales.columns)\n",
    "sales.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import useful functions from previous notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** If you’re using Python: To do the matrix operations required to perform k nearest neighbors, we will be using the popular python library ‘numpy’ which is a computational library specialized for operations on arrays.\n",
    "\n",
    "**3.** To efficiently compute pairwise distances among data points, we will convert the SFrame (or dataframe) into a 2D Numpy array. First import the numpy library and create a get_numpy_data() (or equivalent) function that takes a dataset, a list of features (e.g. [‘sqft_living’, ‘bedrooms’]) to be used as inputs, and a name of the output (e.g. ‘price’). It returns a ‘features_matrix’ (2D array) consisting of a column of ones followed by columns containing the values of the input features in the data set in the same order as the input list. It also returns an ‘output_array’, which is an array of the values of the output in the dataset (e.g. ‘price’)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_numpy_data(    data_pdframe,   features,   output):\n",
    "\n",
    "# inputs\n",
    "# a pandas dataframe, a list of features (e.g. [‘sqft_living’, ‘bedrooms’]), \n",
    "# and name of the output/response column (e.g. ‘price’)\n",
    "\n",
    "# ouputs\n",
    "#  ‘feature_matrix’ (2D array)\n",
    "#  an ‘output_array’ which is an array of the values of the output in the data set (e.g. ‘price’)\n",
    "\n",
    "# Call like this, collecting return data in a tuple\n",
    "# (example_features, example_output) =  get_numpy_data(sales, ['sqft_living'], 'price')\n",
    "# NB., sales is the pdFrame, features_list = ['sqft_living', ....], response = 'price')\n",
    "   \n",
    "#we don't really need to add a constant 1 col and will get same results with or without constant=1 col\n",
    "def get_numpy_data(data_pdframe, features, output):\n",
    "    \n",
    "    data_pdframe['constant'] = 1 # this is how you add a new column to an dataframe\n",
    "    \n",
    "    # add the column 'constant' to the FRONT of the features list \n",
    "    # so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # add two lists\n",
    "    \n",
    "    #NB features = 'constant' + features  wont work!! - can't add string constant to a list\n",
    "    \n",
    "    #print \"get_numpy_data(): Features\", features, \"\\n\"  \n",
    "    \n",
    "    # select the columns of data_pdFrame given by the features list \n",
    "    # into the pdFrame features_pdframe (now including constant 1 col):\n",
    "    features_pdframe = data_pdframe[features]\n",
    "    \n",
    "    print \"get_numpy_data(): print features_pdframe(head(2)\\n\",features_pdframe.head(2), \"\\n\"  \n",
    "    #prints the 2 columns n its values, constant and sqft_living\n",
    "    \n",
    "    # Convert the pdframe to its Numpy-array representation.\n",
    "    # feature_matrix = features_sframe.to_numpy()    #if sframe , use .to_numpy()\n",
    "    feature_matrix = features_pdframe.as_matrix()    #if pdframe ,use .as_matrix() \n",
    "    len(feature_matrix)\n",
    "    print \"get_numpy_data(): print features_pdframe.as_matrix()[0:2, :]\\n\",feature_matrix[0:2, :] , \"\\n\" \n",
    "    \n",
    "    # assign the column of data_pdframe associated with the output to the SArray output_sarray\n",
    "    output_sarray = data_pdframe[output]\n",
    "    print \"get_numpy_data(): data_pdframe['price']\\n\", output_sarray.head(2), \"\\n\"\n",
    "    \n",
    "    # Convert the pdframe column - a series to its Numpy-array representation.\n",
    "    # output_array = output_sarray.to_numpy()   #if column is sframe column  i.e a sarray\n",
    "    output_array = output_sarray.as_matrix()    #if column is pdframe column i.e a series\n",
    "    print \"get_numpy_data(): data_pdframe['price'].as_matrix()\\n\", output_array[0:2], \"\\n\"\n",
    "    \n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** In the house dataset, features vary wildly in their relative magnitude: sqft_living is very large overall compared to bedrooms, for instance. In computing distances, it is crucial to normalize features. Otherwise, for example, the sqft_living feature (typically on the order of thousands) would exert a much larger influence on distance than the bedrooms feature (typically on the order of ones). We divide each column of the training feature matrix by its 2-norm, so that the transformed column has unit norm.\n",
    "\n",
    "To give equal considerations for all features, we need to normalize features: we divide each feature by its 2-norm so that the transformed feature has norm 1. Given a feature matrix, each column is divided (element-wise) by its 2-norm. The function returns two items: (i) a feature matrix with normalized columns and (ii) the norms of the original columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide each feature by its 2-norm, axis=0 --> columns, so divide values in column by its 2-norm\n",
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix, axis=0)    \n",
    "    normalized_features = feature_matrix/ norms\n",
    "    \n",
    "    return  (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training, test, and validation sets\n",
    "\n",
    "**5.** Using get_numpy_data (or equivalent), extract numpy arrays of the training, test, and validation sets - will do this after we split data into train, validate and test sets. Since we not using graphlab, we are provided dat sets that are already split so as to get reproducible results to those using graphlab create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./kc_house_data_small_train.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('./kc_house_data_small_validation.csv', dtype=dtype_dict)\n",
    "test = pd.read_csv('./kc_house_data_small_test.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features and normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all of the numerical inputs listed in `feature_list`, transform the training, test, and validation SFrames into Numpy arrays: (NB **Nearest Neihbour only works with numerical features!!!  really...**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_numpy_data(): print features_pdframe(head(2)\n",
      "   constant  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
      "0         1       3.0       1.00       1180.0      5650     1.0           0   \n",
      "1         1       3.0       2.25       2570.0      7242     2.0           0   \n",
      "\n",
      "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
      "0     0          3      7        1180              0      1955             0   \n",
      "1     0          3      7        2170            400      1951          1991   \n",
      "\n",
      "       lat     long  sqft_living15  sqft_lot15  \n",
      "0  47.5112 -122.257         1340.0      5650.0  \n",
      "1  47.7210 -122.319         1690.0      7639.0   \n",
      "\n",
      "get_numpy_data(): print features_pdframe.as_matrix()[0:2, :]\n",
      "[[  1.00000000e+00   3.00000000e+00   1.00000000e+00   1.18000000e+03\n",
      "    5.65000000e+03   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    3.00000000e+00   7.00000000e+00   1.18000000e+03   0.00000000e+00\n",
      "    1.95500000e+03   0.00000000e+00   4.75112000e+01  -1.22257000e+02\n",
      "    1.34000000e+03   5.65000000e+03]\n",
      " [  1.00000000e+00   3.00000000e+00   2.25000000e+00   2.57000000e+03\n",
      "    7.24200000e+03   2.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    3.00000000e+00   7.00000000e+00   2.17000000e+03   4.00000000e+02\n",
      "    1.95100000e+03   1.99100000e+03   4.77210000e+01  -1.22319000e+02\n",
      "    1.69000000e+03   7.63900000e+03]] \n",
      "\n",
      "get_numpy_data(): data_pdframe['price']\n",
      "0    221900.0\n",
      "1    538000.0\n",
      "Name: price, dtype: float64 \n",
      "\n",
      "get_numpy_data(): data_pdframe['price'].as_matrix()\n",
      "[ 221900.  538000.] \n",
      "\n",
      "get_numpy_data(): print features_pdframe(head(2)\n",
      "   constant  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
      "0         1       4.0        3.0       2950.0      5000     2.0           0   \n",
      "1         1       4.0        1.0       1600.0      4300     1.5           0   \n",
      "\n",
      "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
      "0     3          3      9        1980            970      1979             0   \n",
      "1     0          4      7        1600              0      1916             0   \n",
      "\n",
      "       lat     long  sqft_living15  sqft_lot15  \n",
      "0  47.5714 -122.375         2140.0      4000.0  \n",
      "1  47.6648 -122.343         1610.0      4300.0   \n",
      "\n",
      "get_numpy_data(): print features_pdframe.as_matrix()[0:2, :]\n",
      "[[  1.00000000e+00   4.00000000e+00   3.00000000e+00   2.95000000e+03\n",
      "    5.00000000e+03   2.00000000e+00   0.00000000e+00   3.00000000e+00\n",
      "    3.00000000e+00   9.00000000e+00   1.98000000e+03   9.70000000e+02\n",
      "    1.97900000e+03   0.00000000e+00   4.75714000e+01  -1.22375000e+02\n",
      "    2.14000000e+03   4.00000000e+03]\n",
      " [  1.00000000e+00   4.00000000e+00   1.00000000e+00   1.60000000e+03\n",
      "    4.30000000e+03   1.50000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    4.00000000e+00   7.00000000e+00   1.60000000e+03   0.00000000e+00\n",
      "    1.91600000e+03   0.00000000e+00   4.76648000e+01  -1.22343000e+02\n",
      "    1.61000000e+03   4.30000000e+03]] \n",
      "\n",
      "get_numpy_data(): data_pdframe['price']\n",
      "0    650000.0\n",
      "1    485000.0\n",
      "Name: price, dtype: float64 \n",
      "\n",
      "get_numpy_data(): data_pdframe['price'].as_matrix()\n",
      "[ 650000.  485000.] \n",
      "\n",
      "get_numpy_data(): print features_pdframe(head(2)\n",
      "   constant  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
      "0         1       4.0       1.75       1620.0      4980     1.0           0   \n",
      "1         1       5.0       2.50       2270.0      6300     2.0           0   \n",
      "\n",
      "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
      "0     0          4      7         860            760      1947             0   \n",
      "1     0          3      8        2270              0      1995             0   \n",
      "\n",
      "       lat     long  sqft_living15  sqft_lot15  \n",
      "0  47.7025 -122.341         1400.0      4980.0  \n",
      "1  47.3266 -122.169         2240.0      7005.0   \n",
      "\n",
      "get_numpy_data(): print features_pdframe.as_matrix()[0:2, :]\n",
      "[[  1.00000000e+00   4.00000000e+00   1.75000000e+00   1.62000000e+03\n",
      "    4.98000000e+03   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    4.00000000e+00   7.00000000e+00   8.60000000e+02   7.60000000e+02\n",
      "    1.94700000e+03   0.00000000e+00   4.77025000e+01  -1.22341000e+02\n",
      "    1.40000000e+03   4.98000000e+03]\n",
      " [  1.00000000e+00   5.00000000e+00   2.50000000e+00   2.27000000e+03\n",
      "    6.30000000e+03   2.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    3.00000000e+00   8.00000000e+00   2.27000000e+03   0.00000000e+00\n",
      "    1.99500000e+03   0.00000000e+00   4.73266000e+01  -1.22169000e+02\n",
      "    2.24000000e+03   7.00500000e+03]] \n",
      "\n",
      "get_numpy_data(): data_pdframe['price']\n",
      "0    385000.0\n",
      "1    285000.0\n",
      "Name: price, dtype: float64 \n",
      "\n",
      "get_numpy_data(): data_pdframe['price'].as_matrix()\n",
      "[ 385000.  285000.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_list = ['bedrooms',  \n",
    "                'bathrooms',  \n",
    "                'sqft_living',  \n",
    "                'sqft_lot',  \n",
    "                'floors',\n",
    "                'waterfront',  \n",
    "                'view',  \n",
    "                'condition',  \n",
    "                'grade',  \n",
    "                'sqft_above',  \n",
    "                'sqft_basement',\n",
    "                'yr_built',  \n",
    "                'yr_renovated',  \n",
    "                'lat',  \n",
    "                'long',  \n",
    "                'sqft_living15',  \n",
    "                'sqft_lot15']\n",
    "\n",
    "features_train, output_train = get_numpy_data(train, feature_list, 'price')\n",
    "features_test, output_test = get_numpy_data(test, feature_list, 'price')\n",
    "features_valid, output_valid = get_numpy_data(validation, feature_list, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** In computing distances, it is crucial to normalize features. Otherwise, for example, the `sqft_living` feature (typically on the order of thousands) would exert a much larger influence on distance than the `bedrooms` feature (typically on the order of ones). We **divide each column of the training feature matrix by its 2-norm, so that the transformed column has unit norm.**\n",
    "\n",
    "IMPORTANT: Make sure to store the norms of the features in the training set. The features in the test and validation sets must be divided by these same norms, so that the training, test, and validation sets are normalized consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
      "0       4.0        3.0       2950.0      5000     2.0           0     3   \n",
      "\n",
      "   condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
      "0          3      9        1980            970      1979             0   \n",
      "\n",
      "       lat     long  sqft_living15  sqft_lot15  \n",
      "0  47.5714 -122.375         2140.0      4000.0  \n",
      "[  1.00000000e+00   4.00000000e+00   3.00000000e+00   2.95000000e+03\n",
      "   5.00000000e+03   2.00000000e+00   0.00000000e+00   3.00000000e+00\n",
      "   3.00000000e+00   9.00000000e+00   1.98000000e+03   9.70000000e+02\n",
      "   1.97900000e+03   0.00000000e+00   4.75714000e+01  -1.22375000e+02\n",
      "   2.14000000e+03   4.00000000e+03]\n",
      "[ 0.01345102  0.01551285  0.01807473  0.01759212  0.00160518  0.017059    0.\n",
      "  0.05102365  0.0116321   0.01564352  0.01362084  0.02481682  0.01350306\n",
      "  0.          0.01345387 -0.01346922  0.01375926  0.0016225 ]\n"
     ]
    }
   ],
   "source": [
    "print test[feature_list].head(1)     #test sframe 1st row - 17 features\n",
    "print features_test[0,:]             #test 2D matrix 1st row - 18 values!!!\n",
    "#NB feature_test matrix has extra const col of 1's so 17 features plus const gives size 18 vector\n",
    "\n",
    "# normalize training set features (columns)\n",
    "features_train, norms = normalize_features(features_train) \n",
    "print (features_test[0,:]/norms)\n",
    "\n",
    "# normalize test set and validation set by same training set norms\n",
    "features_test = features_test / norms \n",
    "features_valid = features_valid / norms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute a single distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** To start, let's just explore computing the \"distance\" between two given houses.  We will take our **query house** to be the first house of the test set and look at the distance between this house and the 10th house of the training set.\n",
    "\n",
    "To see the features associated with the query house, print the first row (index 0) of the test feature matrix. You should get an 18-dimensional vector (17 features plus response 'price') whose components are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[ 0.01345102  0.01551285  0.01807473  0.01759212  0.00160518  0.017059    0.\n",
      "  0.05102365  0.0116321   0.01564352  0.01362084  0.02481682  0.01350306\n",
      "  0.          0.01345387 -0.01346922  0.01375926  0.0016225 ]\n"
     ]
    }
   ],
   "source": [
    "# features_test[:,0]    this is 1st column idiot\n",
    "# print len(features_test[:,0]) gave 1741\n",
    "features_test[0,:]    #this is 1st row   - NB the ,: can be dropped if we not splicing the columns\n",
    "# NB this is just 1st row of obs from test data set with only features given above that had been normalized \n",
    "print len(features_test[0,:]) #len(features_test = 1741\n",
    "print features_test[0]        #shud be same as what we got above code segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the 10th row (index 9) of the training feature matrix. Again, you get an 18-dimensional vector with components between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[ 0.01345102  0.01163464  0.00602491  0.0083488   0.00050756  0.01279425\n",
      "  0.          0.          0.01938684  0.01390535  0.0096309   0.\n",
      "  0.01302544  0.          0.01346821 -0.01346251  0.01195898  0.00156612]\n"
     ]
    }
   ],
   "source": [
    "features_train[9,:]            #this is 10th row  - index 9\n",
    "print len(features_train[9,:]) #len(features_train)=5527\n",
    "print features_train[9] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION ***\n",
    "\n",
    "**8.** What is the Euclidean distance between the query house and the 10th house of the training set? \n",
    "\n",
    "Note: Do not use the `np.linalg.norm` function; use `np.sqrt`, `np.sum`, and the power operator (`**`) instead. The latter approach is more easily adapted to computing multiple distances at once. So we do sum of squares of feature-wise differences between test obs and train obs, then sqrt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00  -3.87821276e-03  -1.20498190e-02  -9.24331842e-03\n",
      "  -1.09762322e-03  -4.26475103e-03   0.00000000e+00  -5.10236549e-02\n",
      "   7.75473450e-03  -1.73816863e-03  -3.98994223e-03  -2.48168183e-02\n",
      "  -4.77622244e-04   0.00000000e+00   1.43386859e-05   6.71397301e-06\n",
      "  -1.80027678e-03  -5.63818921e-05]\n",
      "0.059723593714\n"
     ]
    }
   ],
   "source": [
    "#element-wise differences between 1st row test aad 10th row train\n",
    "print  (features_train[9,:] - features_test[0,:])   \n",
    "diff = (features_train[9,:] - features_test[0,:])\n",
    "\n",
    "diff_sum_of_squares = np.sum(diff**2)      #sum of squares of differences\n",
    "eucl_dist = np.sqrt(diff_sum_of_squares)   #sqrt() of squared sum - bit like the 2 norm!!!\n",
    "print eucl_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059723593714\n",
      "0.059723593714\n"
     ]
    }
   ],
   "source": [
    "print np.sqrt(np.sum( (features_train[9,:] - features_test[0,:])**2 ))\n",
    "\n",
    "print np.sqrt(np.sum( (features_train[9] -   features_test[0])**2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute multiple distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** Of course, to do nearest neighbor regression, we need to compute the distance between our query house and *all* houses in the training set. Because we want to **find the shortest distance between test obs and all of train obs**, so we need to find all distances and then min dist as being nearest neighbour in train set to our test obs.  \n",
    "\n",
    "To visualize this nearest-neighbor search, let's first compute the distance from our query house (`features_test[0]`) to the first 10 houses of the training set (`features_train[0:10]`) and then search for the nearest neighbor within this small set of houses.  Through restricting ourselves to a small set of houses to begin with, we can visually scan the list of 10 distances to verify that our code for finding the nearest neighbor is working.\n",
    "\n",
    "Write a loop to compute the Euclidean distance from the query house to each of the first 10 houses in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  0.060274709163\n",
      "1  :  0.0854688114764\n",
      "2  :  0.0614994643528\n",
      "3  :  0.0534027397929\n",
      "4  :  0.0584448406017\n",
      "5  :  0.0598792150981\n",
      "6  :  0.0546314049678\n",
      "7  :  0.0554310832361\n",
      "8  :  0.0523836278402\n",
      "9  :  0.059723593714\n"
     ]
    }
   ],
   "source": [
    "dist = list(xrange(10))\n",
    "for i in xrange(10):\n",
    "    dist[i] = np.sqrt(np.sum( (features_train[i] - features_test[0])**2 ))\n",
    "    print i, \" : \", dist[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION ***\n",
    "\n",
    "**10.** Among the first 10 training houses, which house is the closest to the query house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0523836278402\n",
      "9th house\n"
     ]
    }
   ],
   "source": [
    "print np.min(dist)    #the 9th house from visual inspection above\n",
    "print('%dth house' % (np.argmin(dist) + 1))  #np.argmin() gives index which starts at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11.** It is computationally inefficient to loop over computing distances to all houses in our training dataset. Fortunately, many of the Numpy functions can be **vectorized**, applying the same operation over multiple values or vectors.  We now walk through this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following loop that computes the **element-wise difference between the features**of the query house (`features_test[0]`) and the first 2 training houses (`features_train[0:2]`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00  -3.87821276e-03  -1.20498190e-02  -1.05552733e-02\n",
      "   2.08673616e-04  -8.52950206e-03   0.00000000e+00  -5.10236549e-02\n",
      "   0.00000000e+00  -3.47633726e-03  -5.50336860e-03  -2.48168183e-02\n",
      "  -1.63756198e-04   0.00000000e+00  -1.70254220e-05   1.29876855e-05\n",
      "  -5.14364795e-03   6.69281453e-04] \n",
      "\n",
      "[  0.00000000e+00  -3.87821276e-03  -4.51868214e-03  -2.26610387e-03\n",
      "   7.19763456e-04   0.00000000e+00   0.00000000e+00  -5.10236549e-02\n",
      "   0.00000000e+00  -3.47633726e-03   1.30705004e-03  -1.45830788e-02\n",
      "  -1.91048898e-04   6.65082271e-02   4.23090220e-05   6.16364736e-06\n",
      "  -2.89330197e-03   1.47606982e-03] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(2):\n",
    "    print features_train[i]-features_test[0], \"\\n\"\n",
    "    #dist[i] = np.sqrt(np.sum( (features_train[i] - features_test[0])**2 ))\n",
    "    #print dist[i]\n",
    "    # should print 2 vectors (one for each training house) of length 18\n",
    "    # there are 18 features for a row, so 18 element wise differences, \n",
    "    # one for each difference between test and each train row\n",
    "    # NB 1st col is const 1 so same for both train and test - thus diff always 0\n",
    "    # THis thus implies that the distance computed is sum of absolute differences over all features\n",
    "    # so we don't have feature wise differences!! don't know wht am saying here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subtraction operator (`-`) in Numpy is vectorized as follows: Here we compute the element-wise difference between the features of the query house (features_test[0]) and the first 2 training houses (features_train[0:2]) in one line, and just by giving a row splice [0:2] of train set!! too easy man..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00  -3.87821276e-03  -1.20498190e-02  -1.05552733e-02\n",
      "    2.08673616e-04  -8.52950206e-03   0.00000000e+00  -5.10236549e-02\n",
      "    0.00000000e+00  -3.47633726e-03  -5.50336860e-03  -2.48168183e-02\n",
      "   -1.63756198e-04   0.00000000e+00  -1.70254220e-05   1.29876855e-05\n",
      "   -5.14364795e-03   6.69281453e-04]\n",
      " [  0.00000000e+00  -3.87821276e-03  -4.51868214e-03  -2.26610387e-03\n",
      "    7.19763456e-04   0.00000000e+00   0.00000000e+00  -5.10236549e-02\n",
      "    0.00000000e+00  -3.47633726e-03   1.30705004e-03  -1.45830788e-02\n",
      "   -1.91048898e-04   6.65082271e-02   4.23090220e-05   6.16364736e-06\n",
      "   -2.89330197e-03   1.47606982e-03]]\n"
     ]
    }
   ],
   "source": [
    "print features_train[0:2] - features_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output of this vectorized operation is identical to that of the loop above, which can be verified below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# verify that vectorization works\n",
    "results = features_train[0:3] - features_test[0]\n",
    "print results[0] - ( features_train[0]-features_test[0] )\n",
    "# should print all 0's if results[0] == (features_train[0]-features_test[0])\n",
    "print results[1] - ( features_train[1]-features_test[0] )\n",
    "# should print all 0's if results[1] == (features_train[1]-features_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: it is a good idea to write tests like this cell whenever you are vectorizing a complicated operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform 1-nearest neighbor (1-NN) regression\n",
    "\n",
    "**12.** Now that we have the element-wise differences, it is not too hard to **compute the Euclidean distances between our query house and all of the training houses**. First, write a single-line expression to define a variable `diff` such that `diff[i]` gives the element-wise difference between the features of the query house and the `i`-th training house. So we just calculate element wise differences between test and all observations in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00  -3.87821276e-03  -3.01245476e-03  -8.46807236e-03\n",
      "  -1.24208957e-03   8.52950206e-03   0.00000000e+00  -5.10236549e-02\n",
      "   0.00000000e+00  -1.73816863e-03  -3.09564484e-03  -2.48168183e-02\n",
      "   2.04695248e-04   0.00000000e+00   3.61719513e-05   3.19188881e-06\n",
      "  -3.92203156e-03  -1.01041218e-03]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.093433998746546426"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = features_train[0:len(features_train)] - features_test[0]\n",
    "\n",
    "#18 element-wise feature by feature difference between the query and last training house\n",
    "print diff[len(features_train) - 1]  \n",
    "\n",
    "# sum of the feature differences between the query and last training house\n",
    "np.sum ( diff[ len(features_train) - 1]  ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the code above, run the following cell, which should output a value -0.0934339605842:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5527\n",
      "-0.0934339987465\n",
      "-0.0934339987465\n"
     ]
    }
   ],
   "source": [
    "print len(features_train)\n",
    "# sum of the feature differences between the query and last training house\n",
    "# diff[-1] is the feature wise diff between query and last train house\n",
    "print diff[-1].sum() \n",
    "print np.sum(diff[-1])\n",
    "# both above should print -0.0934339605842"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13.** The next step in **computing the Euclidean distances** is to take these feature-by-feature differences in `diff`, square each, and take the sum over 18 feature indices.  That is, **compute the sum of square of feature differences** for each training house (row in `diff`).\n",
    "\n",
    "By default, **`np.sum` sums up everything in the matrix and returns a single number!!**. To instead **sum only over a row or column, we need to specifiy the `axis` parameter** described in the `np.sum` [documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.sum.html). In particular, **`axis=1` computes the sum across each row** - this is what we want in this case, because each row contains the element-wise feature diffences..\n",
    "\n",
    "Below, we compute this sum of square feature differences for all training houses and verify that the output for the 16th house in the training set is equivalent to having examined only the 16th row of `diff` and computing the sum of squares on that row alone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00330705902846\n",
      "0.00330705902846\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print np.sum(diff**2, axis=1)[15] # take sum of squares across each row, and print the 16th sum\n",
    "print np.sum(diff[15]**2) # print the sum of squares for the 16th row -- should be same as above\n",
    "\n",
    "print (diff[15]**2).sum() == np.sum(diff[15]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.** With this result in mind, write a single-line expression to compute the Euclidean distances between the query house and all houses in the training set. Assign the result to a variable `distances`.\n",
    "\n",
    "**Hint**: Do not forget to take the square root of the sum of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "# distances = np.sqrt(np.sum(diff**2, axis=1)[0:len(features_train)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the code above, find the Euclidean distance between the query house and the 101th training house, which should output a value 0.0237082324496:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0237082324167\n"
     ]
    }
   ],
   "source": [
    "print distances[100] \n",
    "# should print 0.0237082324496"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15.** Now you are ready to write a function that computes the distances from a query house to all training houses. The function should take two parameters: (i) the matrix of training features and (ii) the single feature vector associated with the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_distances(features_instances, features_query):\n",
    "    diff = features_instances - features_query\n",
    "    distances = np.sqrt(  np.sum(diff**2, axis=1))\n",
    "    return distances\n",
    "\n",
    "# Note don't really size or length of train set cause when we leave out row splicing [:]\n",
    "# the whole set of samples is taken, i.e no subsets taken \n",
    "# size = len(features_instances)    <-- this just finds how many samples in train set\n",
    "# diff = features_instances[0:size] - features_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*** QUIZ QUESTIONS 16. and 17. ***\n",
    "\n",
    "1.  Take the query house to be third house of the test set (`features_test[2]`).  What is the index of the house in the training set that is closest to this query house?   382\n",
    "2.  What is the predicted value of the query house based on 1-nearest neighbor regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00286049555751\n",
      "0.00286049555751\n",
      "383th house\n"
     ]
    }
   ],
   "source": [
    "distances = compute_distances(features_train, features_test[2])\n",
    "print min(distances)                  # whats the shortest Euclidean dist\n",
    "min_index = np.argmin(distances)      # index of the shortest Euclidean dist item in numpy array\n",
    "print distances[np.argmin(distances)] # verify \n",
    "print('%dth house' % (min_index + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual value of the query house = $438000\n",
      "Predicted value of the query house = $249000\n",
      "Error of $189000\n"
     ]
    }
   ],
   "source": [
    "# NB with sframes to get value of feature for certain row we did  test[2]['price']\n",
    "# But with pandas dataframe, we have to specify feature col name 1st, then row index\n",
    "print \"Actual value of the query house = $%d\" %test['price'][2]\n",
    "print \"Predicted value of the query house = $%d\" %train['price'][min_index] \n",
    "print \"Error of $%d\" %(test['price'][2] - train['price'][min_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform k-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**18.** So far we have a single house in training set that is closest in distance to our test house, so just 1-NN, but results from 1-NN although having good fit for data dense in x and low noise, not great at interpolating over large regions, also sensitive to noise in data - fits can look quite wild. For k-nearest neighbors, we need to find a *set* of k houses in the training set that are closest to a given query house. We then make predictions based on these k nearest neighbors, by finding mean value of these k houses in train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch k-nearest neighbors\n",
    "\n",
    "Using the functions above, implement a function that takes in\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses; and\n",
    " * the feature vector of the query house\n",
    " \n",
    "and returns the indices of the k closest training houses. For instance, with 2-nearest neighbor, a return value of [5, 10] would indicate that the 6th and 11th training houses are closest to the query house.\n",
    "\n",
    "**Hint**: Look at the [documentation for `np.argsort`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html).   \n",
    "\n",
    "'numpy.argsort(a, axis=-1, kind='quicksort', order=None)' \n",
    "\n",
    "Returns the indices that would sort an array, rather then give sorted values, it gives indices of sorted values... great!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# don't need to reinvent tool - use compute_distances() we already wrote earlier\n",
    "# we sort distances in ascending order and pick 1st k samples as our closest neighbours\n",
    "def k_nearest_neighbors(k, feature_train, features_query):\n",
    "    distances = compute_distances(features_train, features_query)\n",
    "    neighbors = np.argsort(distances)[0:k]   \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION 19. ***\n",
    "\n",
    "Take the query house to be third house of the test set (`features_test[2]`).  What are the indices of the 4 training houses closest to the query house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 382 1149 4087 3142] \n",
      "\n",
      "\n",
      "Predicted price using mean price of nehbours = $413987\n"
     ]
    }
   ],
   "source": [
    "knn_2 =  k_nearest_neighbors(4, features_train, features_test[2])\n",
    "print knn_2, \"\\n\\n\"\n",
    "\n",
    "print \"Predicted price using mean price of nehbours = $%d\" %np.mean(output_train[knn_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a single prediction by averaging k nearest neighbor outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20.** Now that we know how to find the k-nearest neighbors, write a function that predicts the value of a given query house. **For simplicity, take the average of the prices of the k nearest neighbors in the training set**. The function should have the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature vector of the query house, whose price we are predicting.\n",
    " \n",
    "The function should return a predicted value of the query house.\n",
    "\n",
    "**Hint**: You can extract multiple items from a Numpy array using a list of indices. For instance, `output_train[[6, 10]]` returns the prices of the 7th and 11th training houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output_of_query(k, features_train, output_train, features_query):\n",
    "    neighbors = k_nearest_neighbors(k, features_train, features_query)\n",
    "    prices = output_train[neighbors]\n",
    "    prediction = np.mean(prices)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION 21. ***\n",
    "\n",
    "Again taking the query house to be third house of the test set (`features_test[2]`), predict the value of the query house using k-nearest neighbors with `k=4` and the simple averaging method described and implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value $413987.5\n",
      "Actual value of the query house = $438000\n",
      "Error of $24012\n"
     ]
    }
   ],
   "source": [
    "#knn_value = k_nearest_neighbors_value(4, features_train, output_train, features_test[2])\n",
    "predicted_value = predict_output_of_query(4, features_train, output_train, features_test[2])\n",
    "print('Predicted Value $%s' % predicted_value)\n",
    "print \"Actual value of the query house = $%d\" %test['price'][2]\n",
    "print \"Error of $%d\" %(test['price'][2] - predicted_value )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this predicted value using 4-nearest neighbors to the predicted value using 1-nearest neighbor computed earlier.\n",
    "\n",
    "1-nn gave predicted value = \\$249000, which was off by \\$189,000. the 4_nn estimate is only out by \\$24013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make multiple predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22.** Finally, write a function to predict the value of each and every house in a query set. \n",
    "Write a function to predict the value of *each and every* house in a query set. (The query set can be any subset of the dataset, be it the test set or validation set.) The idea is to have a loop where we take each house in the query set as the query house and make a prediction for that specific house. The new function should take the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature matrix for the query set.\n",
    " \n",
    "The function should return a set of predicted values, one for each house in the query set.\n",
    "\n",
    "**Hint**: To get the number of houses in the query set, use the `.shape` field of the query features matrix.  ndarray.shape - gives Tuple of array dimensions.See [the documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.ndarray.shape.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(k, features_train, output_train, features_query):\n",
    "    predictions = []\n",
    "    for i in xrange(len(features_query)):\n",
    "        prediction = predict_output_of_query(k, features_train, output_train, features_query[i])\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is how I did earlier without calling any of the functions we defined earlier\n",
    "# see why it may not not work!!!\n",
    "#def predict_output(k, features_train, output_train, features_test):\n",
    "    \n",
    "#    predictions = []\n",
    "#    size = len(features_train)\n",
    "#    (len_test,col) = features_test.shape\n",
    "#    pred_value = list(xrange(len_test))\n",
    "    \n",
    "#    for i in xrange(len_test):\n",
    "#        diff = features_train[0:size] - features_test[i]\n",
    "#        distances = np.sqrt(  np.sum(diff**2, axis=1)[0:size] )\n",
    "#        indices_of_sorted_distances = np.argsort(distances)\n",
    "#        first_k_indices = list(indices_of_sorted_distances[0:k])\n",
    "#        predictions.append(np.sum(output_train[first_k_indices])/k)\n",
    "    \n",
    "#    return pred_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION 23. ***\n",
    "\n",
    "Make predictions for the first 10 houses in the test set using k-nearest neighbors with `k=10`. \n",
    "\n",
    "1. What is the index of the house in this query set that has the lowest predicted value? \n",
    "2. What is the predicted value of this house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual prices of 10 houses from test set\n",
      "[ 650000.  485000.  438000.  535000.  785000.  975000.  287000.  355000.\n",
      "  305000.  518500.]\n",
      "count        10.000000\n",
      "mean     533350.000000\n",
      "std      218144.453924\n",
      "min      287000.000000\n",
      "25%      375750.000000\n",
      "50%      501750.000000\n",
      "75%      621250.000000\n",
      "max      975000.000000\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Predicted prices of 1st 10 houses from test set using 10-NN from train data\n",
      "[881300.0, 431860.0, 460595.0, 430200.0, 766750.0, 667420.0, 350032.0, 512800.70000000001, 484000.0, 457235.0]\n",
      "count        10.000000\n",
      "mean     544219.270000\n",
      "std      170237.816761\n",
      "min      350032.000000\n",
      "25%      438203.750000\n",
      "50%      472297.500000\n",
      "75%      628765.175000\n",
      "max      881300.000000\n",
      "dtype: float64\n",
      "\n",
      "Index of the house in this query set that has the lowest predicted value 6\n",
      "\n",
      "Lowest predicted value is $350032\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_val = predict_output(10, features_train, output_train, features_test[0:10])\n",
    "\n",
    "print \"Actual prices of 10 houses from test set\\n\", np.array(test[0:10]['price'])\n",
    "print (test[0:10]['price']).describe()\n",
    "print \"\\nPredicted prices of 1st 10 houses from test set using 10-NN from train data\\n\", (knn_val)\n",
    "print pd.Series(knn_val).describe()\n",
    "\n",
    "print \"\\nIndex of the house in this query set that has the lowest predicted value\", np.argmin(knn_val)\n",
    "print \"\\nLowest predicted value is $%d\\n\\n\" %knn_val[np.argmin(knn_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**24.** There remains a question of choosing the value of k to use in making predictions. Here, we use a validation set to choose this value. Write a loop that does the following:\n",
    "\n",
    "* For `k` in [1, 2, ..., 15]:\n",
    "    * Makes predictions for each house in the VALIDATION set using the k-nearest neighbors from the TRAINING set.\n",
    "    * Computes the RSS for these predictions on the VALIDATION set\n",
    "    * Stores the RSS computed above in `rss_all`\n",
    "* Report which `k` produced the lowest RSS on VALIDATION set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Depending on your computing environment, this computation may take 10-15 minutes.)\n",
    "\n",
    "\n",
    "This solution from https://github.com/anindya-saha/Machine-Learning-with-Python/blob/master/Coursera-Machine-Learning-Regression/week-6-local-regression-assignment-graphlab.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_residual_sum_of_squares(predictions, output):  \n",
    "    # Then compute the residuals/errors\n",
    "    residual = output - predictions\n",
    "    # Then square and add them up\n",
    "    residual_squared = residual * residual   \n",
    "    RSS = residual_squared.sum()\n",
    "    return(RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These functions are defined earlier above - reproduced here to enable follow logic\n",
    "def compute_distances(features_instances, features_query):\n",
    "    diff = features_instances - features_query\n",
    "    distances = np.sqrt(  np.sum(diff**2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For k-nearest neighbors, we need to find a set of k houses in the training set closest \n",
    "# to a given query house. We then make predictions based on these k nearest neighbors.\n",
    "def k_nearest_neighbors(k, feature_train, features_query):\n",
    "    distances = compute_distances(features_train, features_query)\n",
    "    neighbors = np.argsort(distances)[0:k]   \n",
    "    return neighbors  #returns k closest obs to given test/query obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a single prediction by averaging k nearest neighbor house values np.mean()\n",
    "# Uses nearest neighbours found by above function\n",
    "def predict_output_of_query(k, features_train, output_train, features_query):\n",
    "    neighbors = k_nearest_neighbors(k, features_train, features_query)\n",
    "    prices = output_train[neighbors]\n",
    "    prediction = np.mean(prices)\n",
    "    return prediction #returns mean price of k closest obs to given test/query obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make multiple predictions\n",
    "# Function to predict the value of each and every house in a query set. \n",
    "# returns a set of predicted values for each house in test using best k neighbours in train\n",
    "def predict_output(k, features_train, output_train, features_query):\n",
    "    predictions = []\n",
    "    for i in xrange(len(features_query)):\n",
    "        prediction = predict_output_of_query(k, features_train, output_train, features_query[i])\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "    return predictions #returns mean price of k closest obs for ALL test/query obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105453830251561.0, 83445073504025.5, 72692096019202.562, 71946721652091.688, 69846517419718.602, 68899544353180.836, 68341973450051.094, 67361678735491.5, 68372727958976.094, 69335048668556.742, 69523855215598.828, 69049969587246.172, 70011254508263.688, 70908698869034.344, 71106928385945.156]\n"
     ]
    }
   ],
   "source": [
    "# we want to find whick value of k produces lowesst error or RSS\n",
    "rss_all = []\n",
    "for k in range(1,16):   \n",
    "    #Makes predictions for each house in the VALIDATION set using the k-nearest neighbors from the TRAINING set.\n",
    "    predicted_values = predict_output(k, features_train, output_train, features_valid)\n",
    "    \n",
    "    #Computes the RSS for these predictions on the VALIDATION set\n",
    "    RSS = get_residual_sum_of_squares(predicted_values, output_valid)\n",
    "    rss_all.append(RSS)\n",
    "    \n",
    "print rss_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another solution from https://github.com/kgrodzicki/machine-learning-specialization/blob/master/course-2-regression/notebooks/week-6-local-regression-assignment-blank.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To visualize the performance as a function of `k`, plot the RSS on the VALIDATION set for each considered `k` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinorda/stats-R/anaconda2/envs/conda_py2.7/lib/python2.7/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEVCAYAAADzUNLBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8faa148350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "kvals = range(1, 16)\n",
    "plt.plot(kvals, rss_all,'bo-')\n",
    "plt.xlabel('Num of Nearest Neghbours = k')\n",
    "plt.ylabel('RSS')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "best_k = rss_all.index(min(rss_all)) + 1 # INDEX FROM 0 !\n",
    "print best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION 25. ***\n",
    "\n",
    "What is the RSS on the TEST data using the value of k found above?  To be clear, sum over all houses in the TEST set. Value of k for which we get lowest rss = 8, so we will look for 8 closest data points in train set for each test obs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33118823552e+14\n"
     ]
    }
   ],
   "source": [
    "best_k = rss_all.index(min(rss_all)) + 1 # INDEX FROM 0 !\n",
    "\n",
    "predicted_values = predict_output(best_k, features_train, output_train, features_test)\n",
    "RSS = get_residual_sum_of_squares(predicted_values, output_test)\n",
    "print(RSS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
