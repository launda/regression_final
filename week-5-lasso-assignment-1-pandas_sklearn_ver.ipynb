{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Ass1: Feature Selection and LASSO (Interpretation)\n",
    "###sklearn version using pandas  - using scikit-learn with Pandas see http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "\n",
    "PWD : TNKSBZ9CT Receipt number 160899085221, 339411363031"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties. The algorithm used to fit the model is Coordinate Descent.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create\n",
    "**0.** Load the sales dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of features = 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>5650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>7639.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0       3.0       1.00       1180.0   \n",
       "1  6414100192  20141209T000000  538000.0       3.0       2.25       2570.0   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0           0     0     ...          7        1180   \n",
       "1      7242     2.0           0     0     ...          7        2170   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0         1340.0      5650.0  \n",
       "1         1690.0      7639.0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, \n",
    "              'sqft_living15':float, 'grade':int, 'yr_renovated':int, \n",
    "              'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, \n",
    "              'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, \n",
    "              'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "sales = pd.read_csv('../Week3/kc_house_data.csv', dtype=dtype_dict)\n",
    "print \"\\nNumber of features = %d\" %len(sales.columns)\n",
    "sales.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Create 4 new features by performing following transformation on inputs: As in Week 2, we consider features that are some transformations of inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'id', u'date', u'price', u'bedrooms', u'bathrooms', u'sqft_living',\n",
      "       u'sqft_lot', u'floors', u'waterfront', u'view', u'condition', u'grade',\n",
      "       u'sqft_above', u'sqft_basement', u'yr_built', u'yr_renovated',\n",
      "       u'zipcode', u'lat', u'long', u'sqft_living15', u'sqft_lot15',\n",
      "       u'sqft_living_sqrt', u'sqft_lot_sqrt', u'bedrooms_square',\n",
      "       u'floors_square'],\n",
      "      dtype='object') \n",
      "Number of features = 25\n"
     ]
    }
   ],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "sales['floors_square'] = sales['floors']*sales['floors']\n",
    "print sales.columns, \"\\nNumber of features = %d\" %len(sales.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Using the entire house dataset, learn regression weights using an L1 penalty of 5e2. Make sure to add \"normalize=True\" when creating the Lasso object. Refer to the following code snippet for the list of features.\n",
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are only going to use 17 features for training and testing.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model  # using scikit-learn\n",
    "\n",
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']\n",
    "print \"We are only going to use %d features for training and testing.\" %len(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in GraphLab Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=500.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all = linear_model.Lasso(alpha=5e2, normalize=True) # set parameters and initialize \n",
    "model_all.fit(sales[all_features], sales['price']) # learn weights by fitting to all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bedrooms', 0.0),\n",
       " ('bedrooms_square', 0.0),\n",
       " ('bathrooms', 0.0),\n",
       " ('sqft_living', 134.43931395540994),\n",
       " ('sqft_living_sqrt', 0.0),\n",
       " ('sqft_lot', 0.0),\n",
       " ('sqft_lot_sqrt', 0.0),\n",
       " ('floors', 0.0),\n",
       " ('floors_square', 0.0),\n",
       " ('waterfront', 0.0),\n",
       " ('view', 24750.004585613766),\n",
       " ('condition', 0.0),\n",
       " ('grade', 61749.103090711593),\n",
       " ('sqft_above', 0.0),\n",
       " ('sqft_basement', 0.0),\n",
       " ('yr_built', -0.0),\n",
       " ('yr_renovated', 0.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(all_features, model_all.coef_)\n",
    "#print  model_all.coefficients[model_all.coefficients['value'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t134.439313955\n",
      "  (0, 10)\t24750.0045856\n",
      "  (0, 12)\t61749.1030907\n",
      "(model_all.coef_).shape[0] 17\n",
      "model_all.sparse_coef_.shape: (1, 17)\n"
     ]
    }
   ],
   "source": [
    "print model_all.sparse_coef_\n",
    "#len(model_all.sparse_coef_)\n",
    "print \"(model_all.coef_).shape[0]\", (model_all.coef_).shape[0]\n",
    "#model_all.sparse_coef_.getnnz\n",
    "print \"model_all.sparse_coef_.shape:\", model_all.sparse_coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. Only 3 out of initial 17 are non-zero. So by **setting a very large L1 penalty**, we are performing a **subset or feature selection**. \n",
    "\n",
    "**3. QUIZ QUESTION Q1: Which features have been chosen by LASSO, i.e. which features were assigned nonzero weights?**\n",
    "According to this list of weights, which of the features have been chosen?  'bathrooms', 'sqft_living', 'sqft_living_sqrt', 'grade', 'sqft_above'\n",
    "\n",
    " \n",
    "Which of the following features have been chosen by LASSO, i.e. which features were assigned nonzero weights? (Choose all that apply)\n",
    "* yr_renovated\n",
    "* waterfront\n",
    "* sqft_living   <----\n",
    "* grade         <----\n",
    "* floors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = pd.read_csv('../Week3/wk3_kc_house_test_data.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('../Week3/wk3_kc_house_train_data.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('../Week3/wk3_kc_house_valid_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure to create the 4 features in ALL 3 data sets:\n",
    "testing['sqft_living_sqrt'] = testing['sqft_living'].apply(sqrt)\n",
    "testing['sqft_lot_sqrt'] = testing['sqft_lot'].apply(sqrt)\n",
    "testing['bedrooms_square'] = testing['bedrooms']*testing['bedrooms']\n",
    "testing['floors_square'] = testing['floors']*testing['floors']\n",
    "\n",
    "training['sqft_living_sqrt'] = training['sqft_living'].apply(sqrt)\n",
    "training['sqft_lot_sqrt'] = training['sqft_lot'].apply(sqrt)\n",
    "training['bedrooms_square'] = training['bedrooms']*training['bedrooms']\n",
    "training['floors_square'] = training['floors']*training['floors']\n",
    "\n",
    "validation['sqft_living_sqrt'] = validation['sqft_living'].apply(sqrt)\n",
    "validation['sqft_lot_sqrt'] = validation['sqft_lot'].apply(sqrt)\n",
    "validation['bedrooms_square'] = validation['bedrooms']*validation['bedrooms']\n",
    "validation['floors_square'] = validation['floors']*validation['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty=5e2` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "l1_penalty = 10.00: non-zero coefficients = 15: rss= 398213327300134.19\n",
      "\n",
      "l1_penalty = 31.62: non-zero coefficients = 15: rss= 399041900253348.19\n",
      "\n",
      "l1_penalty = 100.00: non-zero coefficients = 11: rss= 429791604072558.12\n",
      "\n",
      "l1_penalty = 316.23: non-zero coefficients = 6: rss= 463739831045119.62\n",
      "\n",
      "l1_penalty = 1000.00: non-zero coefficients = 4: rss= 645898733633810.38\n",
      "\n",
      "l1_penalty = 3162.28: non-zero coefficients = 1: rss= 1222506859427156.75\n",
      "\n",
      "l1_penalty = 10000.00: non-zero coefficients = 1: rss= 1222506859427156.75\n",
      "\n",
      "l1_penalty = 31622.78: non-zero coefficients = 1: rss= 1222506859427156.75\n",
      "\n",
      "l1_penalty = 100000.00: non-zero coefficients = 1: rss= 1222506859427156.75\n",
      "\n",
      "l1_penalty = 316227.77: non-zero coefficients = 1: rss= 1222506859427156.75\n",
      "\n",
      "l1_penalty = 1000000.00: non-zero coefficients = 1: rss= 1222506859427156.75\n",
      "\n",
      "l1_penalty = 3162277.66: non-zero coefficients = 1: rss= 1222506859427156.75\n",
      "\n",
      "l1_penalty = 10000000.00: non-zero coefficients = 1: rss= 1222506859427156.75\n",
      "\n",
      "\n",
      "Overall Best l1_penalty on validation data = 10.00, as it gives lowest rss of 398213327300134.19\n"
     ]
    }
   ],
   "source": [
    "penalty_rss = []\n",
    "min_rss = None\n",
    "best_l1_penalty = None\n",
    "best_l1_model = None\n",
    "\n",
    "for l1_penalty in np.logspace(1, 7, num=13):\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True) # set parameters and initialize model\n",
    "    model.fit(training[all_features], training['price'])  # learn weights by fitting to training data\n",
    "    predictions =  model.predict(validation[all_features])# prediction on validation set\n",
    "    residuals = validation['price'] - predictions\n",
    "    rss = (residuals**2).sum()\n",
    "    #RSS.append(rss)\n",
    "    num_non_zeros = np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)\n",
    "    \n",
    "    penalty_rss.append((l1_penalty, rss))\n",
    "    print \"\\nl1_penalty = %0.2f: non-zero coefficients = %d: rss= %0.2f\" \\\n",
    "          %(l1_penalty, num_non_zeros, rss)    \n",
    "    \n",
    "    if min_rss is None or rss < min_rss:\n",
    "        min_rss = rss\n",
    "        best_l1_penalty = l1_penalty\n",
    "        best_l1_model = model\n",
    "      \n",
    "print \"\\n\\nOverall Best l1_penalty on validation data = %0.2f, as it gives lowest rss of %0.2f\" %(best_l1_penalty,min_rss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10.0\n",
      "The best model has 1 non zero coefficients, its RSS on validation is 3.982133273e+14 for a lambda of 10.0\n"
     ]
    }
   ],
   "source": [
    "penalty_rss = sorted(penalty_rss, key = lambda x : x[1])\n",
    "non_zeros = np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)\n",
    "\n",
    "l1_penalty_best = penalty_rss[0][0]\n",
    "print(l1_penalty_best)\n",
    "\n",
    "print \"The best model has\", non_zeros, \"non zero coefficients, its RSS on validation is\",\\\n",
    "min_rss, \"for a lambda of\", best_l1_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** 6. QUIZ QUESTIONS Q2: Which was the best value for the l1_penalty, i.e. which value of l1_penalty produced the lowest RSS on VALIDATION data?***\n",
    "1. What was the best value for the `l1_penalty`? 10.0\n",
    "2. What is the RSS on TEST data of the model with the best `l1_penalty`? 514597632122622.88 (sklearn) 625766285142460.50(gl)\n",
    "\n",
    "\n",
    "In which of the following ranges does the best l1_penalty fall?\n",
    "* Between 0 and 100    <----\n",
    "* Between 100 and 1000\n",
    "* Between 1000 and 10000\n",
    "* Between 10000 and 100000\n",
    "* Greater than 100000\n",
    "\n",
    "**7.** Now that you have selected an L1 penalty, compute the RSS on TEST data for the model with the best L1 penalty - dome see above.  We had saved the model for best L1 earlier so we can just predict using that model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.84674025527e+13\n"
     ]
    }
   ],
   "source": [
    "predictions =  best_l1_model.predict(testing[all_features])  # prediction on validation\n",
    "residuals = testing['price'] - predictions\n",
    "rss = (residuals**2).sum()\n",
    "print rss       #1.56983602382e+14   much higher test RSS using graphlabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use best L1 identified earlier and train on training data using that L1, then test on test data. Shud get same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.84674025527e+13\n"
     ]
    }
   ],
   "source": [
    "model_best_l1 = linear_model.Lasso(alpha=best_l1_penalty, normalize=True) # set parameters and initialize model\n",
    "model_best_l1.fit(training[all_features], training['price'])  # learn weights using best_l1_penalty\n",
    "\n",
    "predictions =  model_best_l1.predict(testing[all_features])  # prediction on test data\n",
    "residuals = testing['price'] - predictions\n",
    "rss = (residuals**2).sum()\n",
    "print rss       #1.56983602382e+14   much higher test RSS using graphlabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. QUIZ QUESTION: Using the best L1 penalty, how many nonzero weights do you have? Count the number of nonzero coefficients first, and add 1 if the intercept is also nonzero.** \n",
    "\n",
    " A succinct way to do this using numpy is \n",
    " \n",
    " *np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)*\n",
    " \n",
    " 15 non-zero, have 17 features so 17 coef plus 1 intercept - tolal 18, 15 non-zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.61445628e+04   3.73245384e+02   5.08412433e+04   6.17853560e+02\n",
      "  -4.44113549e+04   7.85623065e-01  -7.01194765e+02  -0.00000000e+00\n",
      "   5.01420046e+03   6.19488752e+05   3.80418557e+04   2.49987718e+04\n",
      "   1.28716235e+05   0.00000000e+00   0.00000000e+00  -3.29383118e+03\n",
      "   1.00573209e+01]\n",
      "Intercept 6630155.66863\n",
      "  (0, 0)\t-16144.5627571\n",
      "  (0, 1)\t373.245384349\n",
      "  (0, 2)\t50841.2433399\n",
      "  (0, 3)\t617.853559504\n",
      "  (0, 4)\t-44411.3548667\n",
      "  (0, 5)\t0.785623064832\n",
      "  (0, 6)\t-701.194765368\n",
      "  (0, 8)\t5014.20045697\n",
      "  (0, 9)\t619488.752486\n",
      "  (0, 10)\t38041.8556525\n",
      "  (0, 11)\t24998.7718382\n",
      "  (0, 12)\t128716.234621\n",
      "  (0, 15)\t-3293.83117995\n",
      "  (0, 16)\t10.0573208643\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "#print len(model_best_l1.coefficients[model_best_l1.coefficients['value'] != 0])\n",
    "#print model_best_l1.coefficients[model_best_l1.coefficients['value'] != 0]. \\\n",
    "#                                      print_rows(num_rows=20, num_columns=4)\n",
    "print model_best_l1.coef_\n",
    "print \"Intercept\", model_best_l1.intercept_\n",
    "print model_best_l1.sparse_coef_\n",
    "\n",
    "# NOte unlike with graph labs implementation of Lasso - with sklearn 3 coeffificients are exactly zero!!!\n",
    "non_zeros = np.count_nonzero(model_best_l1.coef_) + np.count_nonzero(model_best_l1.intercept_)\n",
    "print non_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "**9.** What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`.\n",
    "\n",
    "**10.** Assign 7 to the variable â€˜max_nonzerosâ€™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "**11.** Exploring large range of l1_penalty, so let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(1, 4, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "l1_penalty = 127.43: non-zero coefficients = 10\n",
      "\n",
      "l1_penalty = 134.60: non-zero coefficients = 10\n",
      "\n",
      "l1_penalty = 141.77: non-zero coefficients = 8\n",
      "\n",
      "l1_penalty = 148.94: non-zero coefficients = 8\n",
      "\n",
      "l1_penalty = 156.11: non-zero coefficients = 7\n",
      "\n",
      "l1_penalty = 163.28: non-zero coefficients = 7\n",
      "\n",
      "l1_penalty = 170.45: non-zero coefficients = 7\n",
      "\n",
      "l1_penalty = 177.62: non-zero coefficients = 7\n",
      "\n",
      "l1_penalty = 184.79: non-zero coefficients = 7\n",
      "\n",
      "l1_penalty = 191.96: non-zero coefficients = 7\n",
      "\n",
      "l1_penalty = 199.13: non-zero coefficients = 7\n",
      "\n",
      "l1_penalty = 206.30: non-zero coefficients = 6\n",
      "\n",
      "l1_penalty = 213.47: non-zero coefficients = 6\n",
      "\n",
      "l1_penalty = 220.64: non-zero coefficients = 6\n",
      "\n",
      "l1_penalty = 227.81: non-zero coefficients = 6\n",
      "\n",
      "l1_penalty = 234.98: non-zero coefficients = 6\n",
      "\n",
      "l1_penalty = 242.15: non-zero coefficients = 6\n",
      "\n",
      "l1_penalty = 249.32: non-zero coefficients = 6\n",
      "\n",
      "l1_penalty = 256.49: non-zero coefficients = 6\n",
      "\n",
      "l1_penalty = 263.67: non-zero coefficients = 6\n",
      "\n",
      "[(127.42749857031335, 10), (134.59789811256189, 10), (141.76829765481045, 8), (148.93869719705901, 8), (156.10909673930755, 7), (163.27949628155611, 7), (170.44989582380464, 7), (177.6202953660532, 7), (184.79069490830176, 7), (191.96109445055032, 7), (199.13149399279888, 7), (206.30189353504741, 6), (213.47229307729594, 6), (220.6426926195445, 6), (227.81309216179307, 6), (234.98349170404163, 6), (242.15389124629019, 6), (249.32429078853872, 6), (256.49469033078725, 6), (263.66508987303581, 6)]\n",
      "\n",
      "The largest l1_penalty that has more non-zeros than 7 is 148.94 with 8 non-zero coefs\n",
      "\n",
      "The smallest l1_penalty that has fewer non-zeros than 7 is 206.30 with 6 non-zero coefs\n"
     ]
    }
   ],
   "source": [
    "nonzero_list = list()\n",
    "l1_penalty_min = None\n",
    "l1_penalty_max = None\n",
    "\n",
    "for l1_penalty in l1_penalty_values:\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True) # set parameters and initialize model\n",
    "    model.fit(training[all_features], training['price'])  # learn weights\n",
    "\n",
    "    num_nonzero_coef = np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)\n",
    "    nonzero_list.append( (l1_penalty, num_nonzero_coef) )\n",
    "    # create a list of tuples\n",
    "\n",
    "    print \"\\nl1_penalty = %0.2f: non-zero coefficients = %d\" \\\n",
    "          %(l1_penalty, num_nonzero_coef)    \n",
    "           \n",
    "    if ( l1_penalty_min  is None) or (num_nonzero_coef > max_nonzeros):\n",
    "        l1_penalty_min = l1_penalty\n",
    "        nonzero_coef_max = num_nonzero_coef\n",
    "    \n",
    "    if (l1_penalty_max is None) and (num_nonzero_coef < max_nonzeros):\n",
    "        l1_penalty_max = l1_penalty\n",
    "        nonzero_coef_min = num_nonzero_coef\n",
    "        \n",
    "print \"\\n\", nonzero_list       \n",
    "print \"\\nThe largest l1_penalty that has more non-zeros than %d is %0.2f with %d non-zero coefs\" \\\n",
    "%(max_nonzeros, l1_penalty_min, nonzero_coef_max )    \n",
    "print \"\\nThe smallest l1_penalty that has fewer non-zeros than %d is %0.2f with %d non-zero coefs\" \\\n",
    "%(max_nonzeros, l1_penalty_max, nonzero_coef_min)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12.** Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzero` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzero` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above.... we did this above in the loop\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries - we do this below.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148.93869719705901, 206.30189353504741)\n"
     ]
    }
   ],
   "source": [
    "# just showing off list comprehension that also works and for loop will be much smaller above\n",
    "# this uses list of tuple created in loop above\n",
    "# `nonzero_list.append( (l1_penalty, num_nonzero_coef) )` \n",
    "l1_penalty_min = max([t[0] for t in nonzero_list if t[1] > max_nonzeros])\n",
    "l1_penalty_max = min([t[0] for t in nonzero_list if t[1] < max_nonzeros])\n",
    "print(l1_penalty_min, l1_penalty_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.938697197\n",
      "206.301893535\n"
     ]
    }
   ],
   "source": [
    "print l1_penalty_min\n",
    "print l1_penalty_max\n",
    "#2976351441.63 using gl we got these\n",
    "#3792690190.73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***13. QUIZ QUESTIONS Q4\n",
    "What values did you find for `l1_penalty_min` and `l1_penalty_max`? ***\n",
    "\n",
    "If you are using GraphLab Create, enter your answer in simple decimals without commas (e.g. 1131000000), rounded to nearest millions.\n",
    "\n",
    "If you are using scikit-learn, enter your answer in simple decimals without commas (e.g. 4313), rounded to nearest integer. \n",
    "`l1_penalty_min` 149 ,`l1_penalty_max` 206"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "**14.** Exploring narrower range/region of `l1_penalty` values we found:between â€˜l1_penalty_minâ€™ and â€˜l1_penalty_maxâ€™. We look for the L1 penalty in this range that produces **exactly the right number of nonzeros AND also minimizes RSS on the VALIDATION set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "**15.** Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "l1_penalty = 148.94: non-zero coefficients = 8: rss= 439158937799659.38\n",
      "\n",
      "l1_penalty = 151.96: non-zero coefficients = 8: rss= 439566717107617.06\n",
      "\n",
      "l1_penalty = 154.98: non-zero coefficients = 7: rss= 439925583107807.88\n",
      "\n",
      "l1_penalty = 158.00: non-zero coefficients = 7: rss= 440228446594392.94\n",
      "\n",
      "l1_penalty = 161.02: non-zero coefficients = 7: rss= 440538757277617.25\n",
      "\n",
      "l1_penalty = 164.03: non-zero coefficients = 7: rss= 440858188572511.06\n",
      "\n",
      "l1_penalty = 167.05: non-zero coefficients = 7: rss= 441186575552993.31\n",
      "\n",
      "l1_penalty = 170.07: non-zero coefficients = 7: rss= 441523902274328.62\n",
      "\n",
      "l1_penalty = 173.09: non-zero coefficients = 7: rss= 441870188649273.94\n",
      "\n",
      "l1_penalty = 176.11: non-zero coefficients = 7: rss= 442225434677828.06\n",
      "\n",
      "l1_penalty = 179.13: non-zero coefficients = 7: rss= 442589625511468.50\n",
      "\n",
      "l1_penalty = 182.15: non-zero coefficients = 7: rss= 442962820579928.69\n",
      "\n",
      "l1_penalty = 185.17: non-zero coefficients = 7: rss= 443344976391377.56\n",
      "\n",
      "l1_penalty = 188.19: non-zero coefficients = 7: rss= 443736092945815.69\n",
      "\n",
      "l1_penalty = 191.21: non-zero coefficients = 7: rss= 444138394032603.31\n",
      "\n",
      "l1_penalty = 194.23: non-zero coefficients = 7: rss= 444547300021443.50\n",
      "\n",
      "l1_penalty = 197.24: non-zero coefficients = 7: rss= 444965116985095.38\n",
      "\n",
      "l1_penalty = 200.26: non-zero coefficients = 7: rss= 445391765725610.12\n",
      "\n",
      "l1_penalty = 203.28: non-zero coefficients = 7: rss= 445827166433146.38\n",
      "\n",
      "l1_penalty = 206.30: non-zero coefficients = 6: rss= 446268896864705.62\n",
      "\n",
      "\n",
      "Overall Best l1_penalty on validation data = 154.98, as it gives lowest rss of 439925583107807.88\n"
     ]
    }
   ],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)\n",
    "penalty_rss_model = []\n",
    "min_rss = None\n",
    "best_l1_penalty = None\n",
    "best_model = None\n",
    "\n",
    "for l1_penalty in l1_penalty_values :\n",
    "    \n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True) # set parameters and initialize model\n",
    "    model.fit(training[all_features], training['price'])         # learn weights\n",
    "\n",
    "    num_nonzero_coef = np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)\n",
    "    # nonzero_list.append(num_nonzero_coef)\n",
    "       \n",
    "    predictions = model.predict(validation[all_features])\n",
    "    residuals = validation['price'] - predictions\n",
    "    rss = (residuals**2).sum()\n",
    "    \n",
    "    print \"\\nl1_penalty = %0.2f: non-zero coefficients = %d: rss= %0.2f\" \\\n",
    "          %(l1_penalty, num_nonzero_coef, rss)\n",
    "        \n",
    "    if (num_nonzero_coef == max_nonzeros) and (min_rss is None or rss < min_rss):\n",
    "        min_rss = rss\n",
    "        best_l1_penalty = l1_penalty\n",
    "        best_model = model\n",
    "        penalty_rss_model.append((l1_penalty, rss, model))\n",
    "\n",
    "        \n",
    "print \"\\n\\nOverall Best l1_penalty on validation data = %0.2f, as it gives lowest rss of %0.2f\" %(best_l1_penalty,min_rss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has 7 non zero coefficients, its RSS is on validation 4.39925583108e+14 for a lambda of 154.976928391\n",
      "[ -0.00000000e+00  -0.00000000e+00   1.08488432e+04   1.63305308e+02\n",
      "   0.00000000e+00  -0.00000000e+00  -0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   5.07353781e+05   4.19793395e+04   0.00000000e+00\n",
      "   1.16371869e+05   0.00000000e+00   0.00000000e+00  -2.62047793e+03\n",
      "   0.00000000e+00]\n",
      "Intercept 6630155.66863\n",
      "  (0, 2)\t10848.8431638\n",
      "  (0, 3)\t163.305307806\n",
      "  (0, 9)\t507353.780812\n",
      "  (0, 10)\t41979.339539\n",
      "  (0, 12)\t116371.869245\n",
      "  (0, 15)\t-2620.47792827\n"
     ]
    }
   ],
   "source": [
    "non_zeros = np.count_nonzero(best_model.coef_) + np.count_nonzero(best_model.intercept_)\n",
    "\n",
    "print \"The best model has\", non_zeros, \"non zero coefficients, its RSS is on validation\", \\\n",
    "min_rss, \"for a lambda of\", best_l1_penalty\n",
    "\n",
    "print best_model.coef_\n",
    "print \"Intercept\", model_best_l1.intercept_\n",
    "print best_model.sparse_coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bedrooms', -0.0),\n",
       " ('bedrooms_square', -0.0),\n",
       " ('bathrooms', 10848.843163831263),\n",
       " ('sqft_living', 163.30530780619353),\n",
       " ('sqft_living_sqrt', 0.0),\n",
       " ('sqft_lot', -0.0),\n",
       " ('sqft_lot_sqrt', -0.0),\n",
       " ('floors', 0.0),\n",
       " ('floors_square', 0.0),\n",
       " ('waterfront', 507353.78081239725),\n",
       " ('view', 41979.339539015469),\n",
       " ('condition', 0.0),\n",
       " ('grade', 116371.86924520371),\n",
       " ('sqft_above', 0.0),\n",
       " ('sqft_basement', 0.0),\n",
       " ('yr_built', -2620.4779282734412),\n",
       " ('yr_renovated', 0.0)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(all_features, best_model.coef_)   #only 6 listed here cause 7th in the intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***16. QUIZ QUESTIONS 5 and 6***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "\n",
    "2. What features in this model have non-zero coefficients?\n",
    "\n",
    "If you are using GraphLab Create, enter your answer in simple decimals without commas (e.g. 1131000000), rounded to nearest millions.  3448000000\n",
    "\n",
    "If you are using scikit-learn, enter your answer in simple decimals without commas (e.g. 4342), rounded to nearest integer. 156\n",
    "\n",
    "Which of the following features has non-zero coefficients? (Choose all that apply)\n",
    "* sqft_living\n",
    "* bedrooms_square\n",
    "* sqft_lot_sqrt  \n",
    "* bathrooms      <<----\n",
    "* floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest rss for 7 non-zero coefs = 439925583107807, with penalty 154 and number of non-zero coeficcients 7\n"
     ]
    }
   ],
   "source": [
    "# we had built a list of tuples in loop above\n",
    "# penalty_rss_model.append((l1_penalty, rss, model))\n",
    "# We can interrogate that list to get lowest rss and its associated lambda and model\n",
    "penalty_rss_model = sorted(penalty_rss_model, key = lambda x : x[1])\n",
    "lowest_rss = penalty_rss_model[0][1]\n",
    "l1_penalty_optimum = penalty_rss_model[0][0]\n",
    "model_optimum = penalty_rss_model[0][2]\n",
    "print \"Lowest rss for 7 non-zero coefs = %d, with penalty %d and number of non-zero coeficcients %d\" \\\n",
    "%(lowest_rss, l1_penalty_optimum, (np.count_nonzero(model_optimum.coef_) + np.count_nonzero(model_optimum.intercept_)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bedrooms', -0.0),\n",
       " ('bedrooms_square', -0.0),\n",
       " ('bathrooms', 10610.890284398485),\n",
       " ('sqft_living', 163.38025164762911),\n",
       " ('sqft_living_sqrt', 0.0),\n",
       " ('sqft_lot', -0.0),\n",
       " ('sqft_lot_sqrt', -0.0),\n",
       " ('floors', 0.0),\n",
       " ('floors_square', 0.0),\n",
       " ('waterfront', 506451.68711485656),\n",
       " ('view', 41960.043554851516),\n",
       " ('condition', 0.0),\n",
       " ('grade', 116253.55369970751),\n",
       " ('sqft_above', 0.0),\n",
       " ('sqft_basement', 0.0),\n",
       " ('yr_built', -2612.2348803574919),\n",
       " ('yr_renovated', 0.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(all_features,best_model.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
